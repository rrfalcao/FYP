{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Paths\n",
    "padded_cusp_image_dir = \"/Users/rfalcao/Documents/FYP/ManualSegmentationAnns/padded/images\"\n",
    "non_cusp_image_dir = \"/Users/rfalcao/Documents/FYP/ManualSegmentationAnns/non_cusp_images\"\n",
    "\n",
    "padded_mask_dir = \"/Users/rfalcao/Documents/FYP/ManualSegmentationAnns/padded/masks\"\n",
    "# Image settings\n",
    "IMG_SIZE = 224  # U-Net or ResNet input size (same size)\n",
    "\n",
    "# Load and preprocess images\n",
    "def load_images(image_dir, mask_dir=None, label=1):\n",
    "    images, masks, labels = [], [], []\n",
    "\n",
    "    for filename in os.listdir(image_dir):\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\"Skipping {filename} (missing image)\")\n",
    "            continue\n",
    "\n",
    "        # Resize to 224x224\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        # Normalize to [0,1]\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = np.expand_dims(img, axis=-1)  # Add channel dim for CNN (e.g., (224, 224, 1))\n",
    "\n",
    "        images.append(img)\n",
    "\n",
    "        # If mask exists, load and process it\n",
    "        if mask_dir:\n",
    "            mask_path = os.path.join(mask_dir, filename)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if mask is not None:\n",
    "                mask = cv2.resize(mask, (IMG_SIZE, IMG_SIZE))  # Resize to match image size\n",
    "                mask = mask.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
    "                mask = np.expand_dims(mask, axis=-1)  # Add channel dim (e.g., (224, 224, 1))\n",
    "                masks.append(mask)\n",
    "            else:\n",
    "                print(f\"Skipping {filename} (missing mask)\")\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(masks) if mask_dir else None, np.array(labels)\n",
    "\n",
    "# Load cusp images & masks\n",
    "cusp_images, cusp_masks, cusp_labels = load_images(padded_cusp_image_dir, padded_mask_dir, label=1)\n",
    "\n",
    "# Load non-cusp images (no masks)\n",
    "non_cusp_images, _, non_cusp_labels = load_images(non_cusp_image_dir, mask_dir=None, label=0)\n",
    "\n",
    "# Combine datasets\n",
    "X = np.concatenate((cusp_images, non_cusp_images), axis=0)\n",
    "y = np.concatenate((cusp_masks, non_cusp_images), axis=0)  # The labels are now the segmentation masks\n",
    "\n",
    "# Shuffle dataset\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "X, y = X[indices], y[indices]\n",
    "\n",
    "# Now, X contains image data and y contains the segmentation mask labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 224, 224, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Model summary\u001b[39;00m\n\u001b[1;32m     38\u001b[0m model \u001b[38;5;241m=\u001b[39m unet_model()\n\u001b[0;32m---> 39\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Assuming you've already prepared your images (X) and masks (Y)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-m2/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-m2/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:767\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m    764\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(output)\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m--> 767\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    768\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    769\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    771\u001b[0m     )\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 224, 224, 1)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "\n",
    "IMG_SIZE = 224  # Input size for ResNet\n",
    "NUM_CLASSES = 1  # Binary classification: cusp or no cusp\n",
    "\n",
    "def unet_model(input_size=(IMG_SIZE, IMG_SIZE, 3)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Contracting path\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    # Bottom part (bottleneck)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "\n",
    "    # Expansive path (upscaling)\n",
    "    up1 = UpSampling2D((2, 2))(conv3)\n",
    "    concat1 = Concatenate()([up1, conv2])\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat1)\n",
    "\n",
    "    up2 = UpSampling2D((2, 2))(conv4)\n",
    "    concat2 = Concatenate()([up2, conv1])\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat2)\n",
    "\n",
    "    # Final layer: Sigmoid for binary segmentation\n",
    "    output = Conv2D(NUM_CLASSES, (1, 1), activation='sigmoid')(conv5)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model summary\n",
    "model = unet_model()\n",
    "history = model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "# Assuming you've already prepared your images (X) and masks (Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-m2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
