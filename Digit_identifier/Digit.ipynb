{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/rfalcao/Documents/train 2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"label\"]  # Copy labels\n",
    "y_train= to_categorical(y_train, num_classes = 10) # One-hot encode the labels\n",
    "train = train.drop(columns=[\"label\"]) / 255  # Normalize without modifying the original\n",
    "train_xCNN=train.to_numpy().reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m295,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">353,226</span> (1.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m353,226\u001b[0m (1.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352,650</span> (1.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m352,650\u001b[0m (1.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> (2.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m576\u001b[0m (2.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_CNN = keras.Sequential([\n",
    "#     keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "#     keras.layers.MaxPooling2D((2,2)),\n",
    "#     keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "#     keras.layers.MaxPooling2D((2,2)),\n",
    "#     keras.layers.Flatten(),\n",
    "#     keras.layers.Dense(128, activation='relu'),\n",
    "#     keras.layers.Dense(10, activation='softmax')  # 10 output classes\n",
    "# ])\n",
    "model_CNN = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, (3,3), strides=2, padding='same', activation='relu'),  # Strided convolution instead of pooling\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.4),  # Regularization\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.4),  # Regularization\n",
    "    keras.layers.Dense(10, activation='softmax')  # 10 output classes\n",
    "])\n",
    "\n",
    "model_CNN.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.10,  \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.7663 - loss: 0.7312 - val_accuracy: 0.9733 - val_loss: 0.0951 - learning_rate: 0.0010\n",
      "Epoch 2/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.2506 - val_accuracy: 0.9724 - val_loss: 0.0967 - learning_rate: 9.8000e-04\n",
      "Epoch 3/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 52ms/step - accuracy: 0.9574 - loss: 0.1443 - val_accuracy: 0.9862 - val_loss: 0.0460 - learning_rate: 9.6040e-04\n",
      "Epoch 4/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.1469 - val_accuracy: 0.9862 - val_loss: 0.0454 - learning_rate: 9.4119e-04\n",
      "Epoch 5/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 48ms/step - accuracy: 0.9680 - loss: 0.1037 - val_accuracy: 0.9743 - val_loss: 0.0856 - learning_rate: 9.2237e-04\n",
      "Epoch 6/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0733 - val_accuracy: 0.9743 - val_loss: 0.0844 - learning_rate: 9.0392e-04\n",
      "Epoch 7/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 47ms/step - accuracy: 0.9708 - loss: 0.0959 - val_accuracy: 0.9831 - val_loss: 0.0531 - learning_rate: 8.8584e-04\n",
      "Epoch 8/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0925 - val_accuracy: 0.9840 - val_loss: 0.0510 - learning_rate: 8.6813e-04\n",
      "Epoch 9/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 47ms/step - accuracy: 0.9756 - loss: 0.0757 - val_accuracy: 0.9912 - val_loss: 0.0315 - learning_rate: 8.5076e-04\n",
      "Epoch 10/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0506 - val_accuracy: 0.9912 - val_loss: 0.0319 - learning_rate: 8.3375e-04\n",
      "Epoch 11/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 48ms/step - accuracy: 0.9777 - loss: 0.0748 - val_accuracy: 0.9812 - val_loss: 0.0563 - learning_rate: 8.1707e-04\n",
      "Epoch 12/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0811 - val_accuracy: 0.9829 - val_loss: 0.0539 - learning_rate: 8.0073e-04\n",
      "Epoch 13/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 55ms/step - accuracy: 0.9802 - loss: 0.0665 - val_accuracy: 0.9867 - val_loss: 0.0456 - learning_rate: 7.8472e-04\n",
      "Epoch 14/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0393 - val_accuracy: 0.9874 - val_loss: 0.0450 - learning_rate: 7.6902e-04\n",
      "Epoch 15/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 47ms/step - accuracy: 0.9828 - loss: 0.0602 - val_accuracy: 0.9886 - val_loss: 0.0374 - learning_rate: 7.5364e-04\n",
      "Epoch 16/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0937 - val_accuracy: 0.9886 - val_loss: 0.0375 - learning_rate: 7.3857e-04\n",
      "Epoch 17/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 48ms/step - accuracy: 0.9838 - loss: 0.0551 - val_accuracy: 0.9876 - val_loss: 0.0409 - learning_rate: 7.2380e-04\n",
      "Epoch 18/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0463 - val_accuracy: 0.9890 - val_loss: 0.0377 - learning_rate: 7.0932e-04\n",
      "Epoch 19/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 48ms/step - accuracy: 0.9845 - loss: 0.0496 - val_accuracy: 0.9924 - val_loss: 0.0242 - learning_rate: 6.9514e-04\n",
      "Epoch 20/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0422 - val_accuracy: 0.9919 - val_loss: 0.0242 - learning_rate: 6.8123e-04\n",
      "Epoch 21/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 48ms/step - accuracy: 0.9837 - loss: 0.0520 - val_accuracy: 0.9864 - val_loss: 0.0479 - learning_rate: 6.6761e-04\n",
      "Epoch 22/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0899 - val_accuracy: 0.9867 - val_loss: 0.0471 - learning_rate: 6.5426e-04\n",
      "Epoch 23/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 48ms/step - accuracy: 0.9857 - loss: 0.0492 - val_accuracy: 0.9931 - val_loss: 0.0236 - learning_rate: 6.4117e-04\n",
      "Epoch 24/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.9933 - val_loss: 0.0238 - learning_rate: 6.2835e-04\n",
      "Epoch 25/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 53ms/step - accuracy: 0.9846 - loss: 0.0493 - val_accuracy: 0.9902 - val_loss: 0.0324 - learning_rate: 6.1578e-04\n",
      "Epoch 26/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0547 - val_accuracy: 0.9907 - val_loss: 0.0325 - learning_rate: 6.0346e-04\n",
      "Epoch 27/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 49ms/step - accuracy: 0.9845 - loss: 0.0519 - val_accuracy: 0.9905 - val_loss: 0.0306 - learning_rate: 5.9140e-04\n",
      "Epoch 28/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0585 - val_accuracy: 0.9905 - val_loss: 0.0300 - learning_rate: 5.7957e-04\n",
      "Epoch 29/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 49ms/step - accuracy: 0.9874 - loss: 0.0412 - val_accuracy: 0.9907 - val_loss: 0.0298 - learning_rate: 5.6798e-04\n",
      "Epoch 30/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9910 - val_loss: 0.0293 - learning_rate: 5.5662e-04\n",
      "Epoch 31/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 50ms/step - accuracy: 0.9865 - loss: 0.0445 - val_accuracy: 0.9926 - val_loss: 0.0195 - learning_rate: 5.4548e-04\n",
      "Epoch 32/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1158 - val_accuracy: 0.9926 - val_loss: 0.0198 - learning_rate: 5.3457e-04\n",
      "Epoch 33/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 52ms/step - accuracy: 0.9885 - loss: 0.0393 - val_accuracy: 0.9926 - val_loss: 0.0261 - learning_rate: 5.2388e-04\n",
      "Epoch 34/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0627 - val_accuracy: 0.9921 - val_loss: 0.0273 - learning_rate: 5.1341e-04\n",
      "Epoch 35/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 52ms/step - accuracy: 0.9876 - loss: 0.0391 - val_accuracy: 0.9926 - val_loss: 0.0233 - learning_rate: 5.0314e-04\n",
      "Epoch 36/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0477 - val_accuracy: 0.9929 - val_loss: 0.0234 - learning_rate: 4.9307e-04\n",
      "Epoch 37/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 48ms/step - accuracy: 0.9882 - loss: 0.0387 - val_accuracy: 0.9912 - val_loss: 0.0242 - learning_rate: 4.8321e-04\n",
      "Epoch 38/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0904 - val_accuracy: 0.9907 - val_loss: 0.0251 - learning_rate: 4.7355e-04\n",
      "Epoch 39/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 53ms/step - accuracy: 0.9891 - loss: 0.0358 - val_accuracy: 0.9948 - val_loss: 0.0178 - learning_rate: 4.6408e-04\n",
      "Epoch 40/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9948 - val_loss: 0.0177 - learning_rate: 4.5480e-04\n",
      "Epoch 41/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 49ms/step - accuracy: 0.9894 - loss: 0.0365 - val_accuracy: 0.9950 - val_loss: 0.0175 - learning_rate: 4.4570e-04\n",
      "Epoch 42/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0415 - val_accuracy: 0.9950 - val_loss: 0.0172 - learning_rate: 4.3679e-04\n",
      "Epoch 43/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 47ms/step - accuracy: 0.9891 - loss: 0.0343 - val_accuracy: 0.9952 - val_loss: 0.0183 - learning_rate: 4.2805e-04\n",
      "Epoch 44/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0312 - val_accuracy: 0.9952 - val_loss: 0.0182 - learning_rate: 4.1949e-04\n",
      "Epoch 45/45\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 48ms/step - accuracy: 0.9896 - loss: 0.0336 - val_accuracy: 0.9952 - val_loss: 0.0172 - learning_rate: 4.1110e-04\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9966 - loss: 0.0121\n",
      "Validation Accuracy: 0.9952\n"
     ]
    }
   ],
   "source": [
    "epochs = 45\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.98 ** x)\n",
    "\n",
    "# Train-test split\n",
    "X_train2, X_val2, Y_train2, Y_val2 = train_test_split(train_xCNN, y_train, test_size=0.1)  # FIXED\n",
    "\n",
    "# Train model\n",
    "history = model_CNN.fit(datagen.flow(X_train2, Y_train2, batch_size=64),  # FIXED\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=len(X_train2) // 64,\n",
    "                        validation_data=(X_val2, Y_val2),\n",
    "                        callbacks=[annealer],\n",
    "                        verbose=1)\n",
    "\n",
    "# Evaluate model\n",
    "val_loss, val_acc = model_CNN.evaluate(X_val2, Y_val2)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_CNN.save('trained_model.h5')\n",
    "model_CNN.save('trained_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "# Load trained model\n",
    "model = load_model('trained_model.h5')\n",
    "\n",
    "def segment_digits_with_labels(image_path):\n",
    "    image = cv2.imread(image_path)  # Read in color (BGR) to allow colored labels\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale for processing\n",
    "    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    digits = []\n",
    "    labels = string.ascii_uppercase  # Excel column labels (A, B, C, D, ...)\n",
    "    label_index = 0  # Start with 'A'\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w > 10 and h > 10:\n",
    "            digit_image = gray[y:y+h, x:x+w]\n",
    "            digit_image_resized = cv2.resize(digit_image, (28, 28))\n",
    "            digit_image_normalized = digit_image_resized / 255.0\n",
    "            digit_image_normalized = digit_image_normalized.reshape(1, 28, 28, 1)\n",
    "\n",
    "            prediction = model.predict(digit_image_normalized)\n",
    "            predicted_digit = np.argmax(prediction)\n",
    "\n",
    "            # Label the bounding box with Excel column labels\n",
    "            label = labels[label_index] if label_index < len(labels) else 'Z'\n",
    "            digits.append((predicted_digit, label, (x, y, w, h)))\n",
    "\n",
    "            # Draw the bounding box\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw label above the box\n",
    "            cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "            # Draw predicted digit below the box\n",
    "            cv2.putText(image, str(predicted_digit), (x, y + h + 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            label_index += 1  # Move to the next label\n",
    "\n",
    "    return image, digits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@18563.985] global loadsave.cpp:268 findDecoder imread_('/Users/rfalcao/Documents/FYP/Digit_identifier/TestSeq2.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/rfalcao/Documents/FYP/Digit_identifier/TestSeq2.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m segmented_image, predicted_digits \u001b[38;5;241m=\u001b[39m \u001b[43msegment_digits_with_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(segmented_image, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 12\u001b[0m, in \u001b[0;36msegment_digits_with_labels\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msegment_digits_with_labels\u001b[39m(image_path):\n\u001b[1;32m     11\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)  \u001b[38;5;66;03m# Read in color (BGR) to allow colored labels\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert to grayscale for processing\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     _, thresh \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(gray, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY_INV)\n\u001b[1;32m     14\u001b[0m     contours, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindContours(thresh, cv2\u001b[38;5;241m.\u001b[39mRETR_EXTERNAL, cv2\u001b[38;5;241m.\u001b[39mCHAIN_APPROX_SIMPLE)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "image_path = '/Users/rfalcao/Documents/FYP/Digit_identifier/TestSeq2.jpg'\n",
    "\n",
    "segmented_image, predicted_digits = segment_digits_with_labels(image_path)\n",
    "\n",
    "# Display the result\n",
    "plt.imshow(segmented_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Print predicted digits with their Excel-like labels\n",
    "for digit, label, position in predicted_digits:\n",
    "    print(f\"Predicted Digit: {digit} at label {label} with position {position}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-m2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
