{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rfalcao/anaconda3/envs/tf-m2/bin/python\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from ipywidgets import Button, HBox, VBox, Output, Layout\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder= '/Users/rfalcao/Documents/Cusp Images - SEM'\n",
    "image_files = sorted(os.listdir(image_folder))\n",
    "image_path = os.path.join(image_folder, image_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Rotation import ImageAlignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images (crop_only): 100%|██████████| 168/168 [01:55<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation Angles: {'E_13.png': 0, 'B_26.png': 0, 'E_2.png': 0, 'C_4.png': 0, 'D_47.png': 0, 'D_53.png': 0, 'A_6.png': 0, 'A_7.png': 0, 'D_52.png': 0, 'D_46.png': 0, 'C_5.png': 0, 'E_3.png': 0, 'B_27.png': 0, 'E_12.png': 0, 'B_19.png': 0, 'E_10.png': 0, 'B_31.png': 0, 'B_25.png': 0, 'E_1.png': 0, 'C_7.png': 0, 'D_50.png': 0, 'D_44.png': 0, 'A_5.png': 0, 'A_4.png': 0, 'D_45.png': 0, 'D_51.png': 0, 'C_6.png': 0, 'B_24.png': 0, 'B_30.png': 0, 'B_18.png': 0, 'E_11.png': 0, 'B_20.png': 0, 'E_15.png': 0, 'E_4.png': 0, 'D_55.png': 0, 'D_41.png': 0, 'C_2.png': 0, 'A_1.png': 0, 'C_3.png': 0, 'D_40.png': 0, 'D_54.png': 0, 'E_5.png': 0, 'E_14.png': 0, 'B_21.png': 0, 'B_23.png': 0, 'E_16.png': 0, 'E_7.png': 0, 'D_42.png': 0, 'D_56.png': 0, 'C_1.png': 0, 'A_3.png': 0, 'A_2.png': 0, 'D_57.png': 0, 'D_43.png': 0, 'E_6.png': 0, 'E_17.png': 0, 'B_22.png': 0, 'A_14.png': 0, 'B_7.png': 0, 'D_18.png': 0, 'C_11.png': 0, 'D_1.png': 0, 'D_24.png': 0, 'D_30.png': 0, 'F_3.png': 0, 'F_2.png': 0, 'D_31.png': 0, 'D_25.png': 0, 'D_19.png': 0, 'C_10.png': 0, 'A_15.png': 0, 'B_6.png': 0, 'B_4.png': 0, 'A_17.png': 0, 'D_2.png': 0, 'C_12.png': 0, 'D_33.png': 0, 'D_27.png': 0, 'F_1.png': 0, 'D_26.png': 0, 'D_32.png': 0, 'C_13.png': 0, 'D_3.png': 0, 'B_5.png': 0, 'A_16.png': 0, 'A_12.png': 0, 'B_1.png': 0, 'D_36.png': 0, 'D_22.png': 0, 'D_7.png': 0, 'C_17.png': 0, 'F_5.png': 0, 'F_4.png': 0, 'C_16.png': 0, 'D_6.png': 0, 'D_23.png': 0, 'D_37.png': 0, 'A_13.png': 0, 'B_2.png': 0, 'A_11.png': 0, 'D_21.png': 0, 'D_35.png': 0, 'C_14.png': 0, 'D_4.png': 0, 'F_6.png': 0, 'F_7.png': 0, 'D_5.png': 0, 'C_15.png': 0, 'D_34.png': 0, 'D_20.png': 0, 'B_3.png': 0, 'A_10.png': 0, 'A_21.png': 0, 'D_39.png': 0, 'D_8.png': 0, 'D_11.png': 0, 'D_10.png': 0, 'D_9.png': 0, 'D_38.png': 0, 'A_20.png': 0, 'A_22.png': 0, 'D_12.png': 0, 'F_9.png': 0, 'F_8.png': 0, 'D_13.png': 0, 'A_23.png': 0, 'B_8.png': 0, 'D_17.png': 0, 'D_16.png': 0, 'B_9.png': 0, 'A_18.png': 0, 'D_14.png': 0, 'D_28.png': 0, 'D_29.png': 0, 'D_15.png': 0, 'A_19.png': 0, 'F_10.png': 0, 'B_13.png': 0, 'D_66.png': 0, 'D_67.png': 0, 'B_12.png': 0, 'E_19.png': 0, 'B_10.png': 0, 'E_8.png': 0, 'D_59.png': 0, 'D_65.png': 0, 'D_64.png': 0, 'D_58.png': 0, 'E_9.png': 0, 'E_18.png': 0, 'B_11.png': 0, 'B_15.png': 0, 'B_29.png': 0, 'E_20.png': 0, 'D_60.png': 0, 'D_48.png': 0, 'A_9.png': 0, 'A_8.png': 0, 'D_49.png': 0, 'D_61.png': 0, 'B_28.png': 0, 'B_14.png': 0, 'B_16.png': 0, 'D_63.png': 0, 'C_8.png': 0, 'D_62.png': 0, 'C_9.png': 0, 'B_17.png': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'E_13.png': 0,\n",
       " 'B_26.png': 0,\n",
       " 'E_2.png': 0,\n",
       " 'C_4.png': 0,\n",
       " 'D_47.png': 0,\n",
       " 'D_53.png': 0,\n",
       " 'A_6.png': 0,\n",
       " 'A_7.png': 0,\n",
       " 'D_52.png': 0,\n",
       " 'D_46.png': 0,\n",
       " 'C_5.png': 0,\n",
       " 'E_3.png': 0,\n",
       " 'B_27.png': 0,\n",
       " 'E_12.png': 0,\n",
       " 'B_19.png': 0,\n",
       " 'E_10.png': 0,\n",
       " 'B_31.png': 0,\n",
       " 'B_25.png': 0,\n",
       " 'E_1.png': 0,\n",
       " 'C_7.png': 0,\n",
       " 'D_50.png': 0,\n",
       " 'D_44.png': 0,\n",
       " 'A_5.png': 0,\n",
       " 'A_4.png': 0,\n",
       " 'D_45.png': 0,\n",
       " 'D_51.png': 0,\n",
       " 'C_6.png': 0,\n",
       " 'B_24.png': 0,\n",
       " 'B_30.png': 0,\n",
       " 'B_18.png': 0,\n",
       " 'E_11.png': 0,\n",
       " 'B_20.png': 0,\n",
       " 'E_15.png': 0,\n",
       " 'E_4.png': 0,\n",
       " 'D_55.png': 0,\n",
       " 'D_41.png': 0,\n",
       " 'C_2.png': 0,\n",
       " 'A_1.png': 0,\n",
       " 'C_3.png': 0,\n",
       " 'D_40.png': 0,\n",
       " 'D_54.png': 0,\n",
       " 'E_5.png': 0,\n",
       " 'E_14.png': 0,\n",
       " 'B_21.png': 0,\n",
       " 'B_23.png': 0,\n",
       " 'E_16.png': 0,\n",
       " 'E_7.png': 0,\n",
       " 'D_42.png': 0,\n",
       " 'D_56.png': 0,\n",
       " 'C_1.png': 0,\n",
       " 'A_3.png': 0,\n",
       " 'A_2.png': 0,\n",
       " 'D_57.png': 0,\n",
       " 'D_43.png': 0,\n",
       " 'E_6.png': 0,\n",
       " 'E_17.png': 0,\n",
       " 'B_22.png': 0,\n",
       " 'A_14.png': 0,\n",
       " 'B_7.png': 0,\n",
       " 'D_18.png': 0,\n",
       " 'C_11.png': 0,\n",
       " 'D_1.png': 0,\n",
       " 'D_24.png': 0,\n",
       " 'D_30.png': 0,\n",
       " 'F_3.png': 0,\n",
       " 'F_2.png': 0,\n",
       " 'D_31.png': 0,\n",
       " 'D_25.png': 0,\n",
       " 'D_19.png': 0,\n",
       " 'C_10.png': 0,\n",
       " 'A_15.png': 0,\n",
       " 'B_6.png': 0,\n",
       " 'B_4.png': 0,\n",
       " 'A_17.png': 0,\n",
       " 'D_2.png': 0,\n",
       " 'C_12.png': 0,\n",
       " 'D_33.png': 0,\n",
       " 'D_27.png': 0,\n",
       " 'F_1.png': 0,\n",
       " 'D_26.png': 0,\n",
       " 'D_32.png': 0,\n",
       " 'C_13.png': 0,\n",
       " 'D_3.png': 0,\n",
       " 'B_5.png': 0,\n",
       " 'A_16.png': 0,\n",
       " 'A_12.png': 0,\n",
       " 'B_1.png': 0,\n",
       " 'D_36.png': 0,\n",
       " 'D_22.png': 0,\n",
       " 'D_7.png': 0,\n",
       " 'C_17.png': 0,\n",
       " 'F_5.png': 0,\n",
       " 'F_4.png': 0,\n",
       " 'C_16.png': 0,\n",
       " 'D_6.png': 0,\n",
       " 'D_23.png': 0,\n",
       " 'D_37.png': 0,\n",
       " 'A_13.png': 0,\n",
       " 'B_2.png': 0,\n",
       " 'A_11.png': 0,\n",
       " 'D_21.png': 0,\n",
       " 'D_35.png': 0,\n",
       " 'C_14.png': 0,\n",
       " 'D_4.png': 0,\n",
       " 'F_6.png': 0,\n",
       " 'F_7.png': 0,\n",
       " 'D_5.png': 0,\n",
       " 'C_15.png': 0,\n",
       " 'D_34.png': 0,\n",
       " 'D_20.png': 0,\n",
       " 'B_3.png': 0,\n",
       " 'A_10.png': 0,\n",
       " 'A_21.png': 0,\n",
       " 'D_39.png': 0,\n",
       " 'D_8.png': 0,\n",
       " 'D_11.png': 0,\n",
       " 'D_10.png': 0,\n",
       " 'D_9.png': 0,\n",
       " 'D_38.png': 0,\n",
       " 'A_20.png': 0,\n",
       " 'A_22.png': 0,\n",
       " 'D_12.png': 0,\n",
       " 'F_9.png': 0,\n",
       " 'F_8.png': 0,\n",
       " 'D_13.png': 0,\n",
       " 'A_23.png': 0,\n",
       " 'B_8.png': 0,\n",
       " 'D_17.png': 0,\n",
       " 'D_16.png': 0,\n",
       " 'B_9.png': 0,\n",
       " 'A_18.png': 0,\n",
       " 'D_14.png': 0,\n",
       " 'D_28.png': 0,\n",
       " 'D_29.png': 0,\n",
       " 'D_15.png': 0,\n",
       " 'A_19.png': 0,\n",
       " 'F_10.png': 0,\n",
       " 'B_13.png': 0,\n",
       " 'D_66.png': 0,\n",
       " 'D_67.png': 0,\n",
       " 'B_12.png': 0,\n",
       " 'E_19.png': 0,\n",
       " 'B_10.png': 0,\n",
       " 'E_8.png': 0,\n",
       " 'D_59.png': 0,\n",
       " 'D_65.png': 0,\n",
       " 'D_64.png': 0,\n",
       " 'D_58.png': 0,\n",
       " 'E_9.png': 0,\n",
       " 'E_18.png': 0,\n",
       " 'B_11.png': 0,\n",
       " 'B_15.png': 0,\n",
       " 'B_29.png': 0,\n",
       " 'E_20.png': 0,\n",
       " 'D_60.png': 0,\n",
       " 'D_48.png': 0,\n",
       " 'A_9.png': 0,\n",
       " 'A_8.png': 0,\n",
       " 'D_49.png': 0,\n",
       " 'D_61.png': 0,\n",
       " 'B_28.png': 0,\n",
       " 'B_14.png': 0,\n",
       " 'B_16.png': 0,\n",
       " 'D_63.png': 0,\n",
       " 'C_8.png': 0,\n",
       " 'D_62.png': 0,\n",
       " 'C_9.png': 0,\n",
       " 'B_17.png': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligner = ImageAlignment('/Users/rfalcao/Documents/FYP/Cusp Images_081224/Unfiltered', '/Users/rfalcao/Documents/FYP/Cusp Images_081224/Clear',False)\n",
    "aligner.process_all_images(method=\"crop_only\") #Methods: 'fft' , 'radon', 'translation' , 'crop_only' , 'all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a73553d6dc4621bf928598526c6bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(), HBox(children=(Button(button_style='success', description='Yes', layout=Layout(width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Button, HBox, VBox, Output, Layout\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def classify_clear_cusp_images(image_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Iterates through images in a folder, displays them for manual classification\n",
    "    using interactive widgets, and saves selected images with clear cusps.\n",
    "\n",
    "    Parameters:\n",
    "        - image_folder: Folder containing images to classify.\n",
    "        - output_folder: Folder where selected images will be saved.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Get list of image files\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.tif'))]\n",
    "    image_index = [0]  # Mutable index to track current image\n",
    "\n",
    "    output = Output()\n",
    "\n",
    "    def update_display():\n",
    "        \"\"\"Updates the display to show the current image.\"\"\"\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            if image_index[0] >= len(image_files):\n",
    "                print(\"Classification complete! Selected images have been saved.\")\n",
    "                return\n",
    "            \n",
    "            # Load and display the current image\n",
    "            filename = image_files[image_index[0]]\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.title(f\"Does this image have clear cusps? \\nFilename: {filename}\")\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    def on_save_clicked(b):\n",
    "        \"\"\"Handles 'Save' button click (move image to output folder).\"\"\"\n",
    "        filename = image_files[image_index[0]]\n",
    "        src_path = os.path.join(image_folder, filename)\n",
    "        dst_path = os.path.join(output_folder, filename)\n",
    "        shutil.copy(src_path, dst_path)  # Copy the image to the new folder\n",
    "        next_image()\n",
    "\n",
    "    def on_skip_clicked(b):\n",
    "        \"\"\"Handles 'Skip' button click.\"\"\"\n",
    "        next_image()\n",
    "\n",
    "    def next_image():\n",
    "        \"\"\"Moves to the next image or ends classification if all are processed.\"\"\"\n",
    "        image_index[0] += 1\n",
    "        update_display()\n",
    "\n",
    "    # Create buttons\n",
    "    save_button = Button(description=\"Yes\", button_style='success', layout=Layout(width='100px'))\n",
    "    skip_button = Button(description=\"No\", button_style='warning', layout=Layout(width='100px'))\n",
    "\n",
    "    save_button.on_click(on_save_clicked)\n",
    "    skip_button.on_click(on_skip_clicked)\n",
    "\n",
    "    # Display UI\n",
    "    controls = HBox([save_button, skip_button])\n",
    "    display(VBox([output, controls]))\n",
    "\n",
    "    update_display()\n",
    "\n",
    "# Paths\n",
    "image_folder = '/Users/rfalcao/Documents/Cusp Images - SEM'  # Replace with the actual folder\n",
    "output_folder = '/Users/rfalcao/Documents/Clear Cusps'  # Replace with the actual folder\n",
    "\n",
    "# Run the classification\n",
    "classify_clear_cusp_images(image_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b681ba2da574b83b022cbfe356afc1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(), HBox(children=(Button(button_style='success', description='Cusp', layout=Layout(width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Button, HBox, VBox, Output, Layout\n",
    "from IPython.display import display, clear_output\n",
    "#LABELING CODE\n",
    "def label_cusps(image_folder):\n",
    "    \"\"\"\n",
    "    Iterates through images in a folder, displays them for manual classification\n",
    "    using interactive widgets, and saves selected images with clear cusps.\n",
    "\n",
    "    Parameters:\n",
    "        - image_folder: Folder containing images to classify.\n",
    "        - output_folder: Folder where selected images will be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Get list of image files\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.tif'))]\n",
    "    image_index = [0]  # Mutable index to track current image\n",
    "    classifications={}\n",
    "    output = Output()\n",
    "\n",
    "    def update_display():\n",
    "        \"\"\"Updates the display to show the current image.\"\"\"\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            if image_index[0] >= len(image_files):\n",
    "                print(\"Labels Complete! Selected images have been saved.\")\n",
    "                return\n",
    "            \n",
    "            # Load and display the current image\n",
    "            filename = image_files[image_index[0]]\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.title(f\"Does this image have clear cusps? \\nFilename: {filename}\")\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    def on_yes_clicked(b):\n",
    "        \"\"\"Handles 'Save' button click (move image to output folder).\"\"\"\n",
    "        filename = image_files[image_index[0]]\n",
    "        classifications[filename]=1\n",
    "        next_image()\n",
    "\n",
    "    def on_no_clicked(b):\n",
    "        filename = image_files[image_index[0]]\n",
    "        classifications[filename]=0\n",
    "        next_image()\n",
    "\n",
    "    def next_image():\n",
    "        \"\"\"Moves to the next image or ends classification if all are processed.\"\"\"\n",
    "        image_index[0] += 1\n",
    "        update_display()\n",
    "\n",
    "    # Create buttons\n",
    "    yes_button = Button(description=\"Cusp\", button_style='success', layout=Layout(width='100px'))\n",
    "    no_button = Button(description=\"No Cusp\", button_style='warning', layout=Layout(width='100px'))\n",
    "\n",
    "    yes_button.on_click(on_yes_clicked)\n",
    "    no_button.on_click(on_no_clicked)\n",
    "\n",
    "    # Display UI\n",
    "    controls = HBox([yes_button, no_button])\n",
    "    display(VBox([output, controls]))\n",
    "\n",
    "    update_display()\n",
    "    return classifications\n",
    "# Paths\n",
    "image_folder = \"/Users/rfalcao/Documents/Separated Clear Cusps\" \n",
    "# Run the classification\n",
    "labels=label_cusps(image_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation code - DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'12_q3_q1_q3_q3.png': 1, '12_q3_q3_q2_q0.png': 1, '12_q3_q3_q2_q1.png': 1, '12_q3_q1_q3_q2.png': 1, '12_q3_q1_q3_q0.png': 1, '12_q3_q3_q2_q3.png': 0, '12_q3_q3_q2_q2.png': 0, '12_q3_q1_q3_q1.png': 1, '12_q3_q3_q0_q3.png': 1, '12_q3_q1_q1_q0.png': 1, '12_q3_q1_q1_q1.png': 1, '12_q3_q3_q0_q2.png': 1, '12_q3_q3_q0_q0.png': 1, '12_q3_q3_q0_q1.png': 1, '12_q2_q1_q3.png': 1, '12_q2_q1_q2.png': 1, '12_q3_q0_q3_q0.png': 1, '12_q2_q1_q0.png': 1, '12_q2_q1_q1.png': 1, '12_q3_q0_q3_q1.png': 1, '8 (1)_q3.png': 1, '11_q3_q0.png': 1, '11_q3_q1.png': 1, '8 (1)_q2.png': 1, '12_q2_q3_q1.png': 1, '8 (1)_q0.png': 1, '11_q3_q2.png': 1, '8 (1)_q1.png': 1, '12_q2_q3_q2.png': 1, '12_q3_q1_q2_q1.png': 1, '12_q3_q3_q3_q2.png': 0, '12_q3_q3_q3_q3.png': 0, '12_q1_q3.png': 1, '12_q3_q1_q2_q0.png': 1, '12_q3_q1_q2_q2.png': 1, '12_q3_q3_q3_q1.png': 0, '12_q1_q1_q0.png': 1, '12_q3_q3_q3_q0.png': 1, '12_q3_q1_q2_q3.png': 1, '12_q3_q3_q1_q1.png': 1, '12_q3_q3_q1_q0.png': 1, '12_q3_q3_q1_q2.png': 1, '12_q3_q1_q0_q1.png': 1, '12_q3_q1_q0_q0.png': 1, '12_q3_q3_q1_q3.png': 1, '12_q3_q2_q0.png': 1, '12_q2_q0_q1.png': 1, '12_q3_q2_q3_q3.png': 0, '2b_i_i_2_1000x_q3_q3.png': 0, '12_q3_q0_q2_q0.png': 1, '12_q2_q0_q2.png': 1, '12_q3_q0_q2_q3.png': 1, '12_q2_q0_q3.png': 1, '11_q2_q2.png': 1, '11_q2_q3.png': 1, '12_q3_q2_q1_q0.png': 1, '12_q3_q2_q1_q2.png': 1, '11_q2_q1.png': 1, '11_q2_q0.png': 1, '12_q3_q2_q1_q3.png': 1}\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1785, 2560)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ac53cf36fc4332a074ec4f6f3aad4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(), HBox(children=(Button(button_style='success', description='Yes (Quarter)', layout=Lay…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Button, HBox, VBox, Output, Layout\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "input_folder = '/Users/rfalcao/Documents/ClearCuspsCroppedRotated'  \n",
    "output_folder = \"/Users/rfalcao/Documents/Separated Clear Cusps\"  \n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "image_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.tif'))]\n",
    "image_queue = image_files[:]  \n",
    "quartered_queue = []  \n",
    "\n",
    "output = Output()\n",
    "\n",
    "def update_display(image, title):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.title(title)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Function to quarter image\n",
    "def quarter_image(image):\n",
    "    h, w = image.shape\n",
    "    half_h, half_w = h // 2, w // 2\n",
    "    return [\n",
    "        image[:half_h, :half_w], image[:half_h, half_w:],\n",
    "        image[half_h:, :half_w], image[half_h:, half_w:]\n",
    "    ]\n",
    "\n",
    "# Function to process next image\n",
    "def next_image():\n",
    "    if quartered_queue:\n",
    "        # Process the most recent quartered image first\n",
    "        q_image, base_name, i = quartered_queue[-1]\n",
    "        update_display(q_image, f\"Quarter {i} of {base_name}\")\n",
    "    elif image_queue:\n",
    "        # Process the next image in the original queue\n",
    "        image_path = image_queue[0]\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        update_display(image, f\"Inspecting: {os.path.basename(image_path)}\")\n",
    "    else:\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            print(\"All images processed!\")\n",
    "\n",
    "# Button callbacks\n",
    "def on_yes_clicked(b):\n",
    "    if quartered_queue:\n",
    "        # Quarter the most recent quartered image\n",
    "        q_image, base_name, i = quartered_queue.pop()\n",
    "        if q_image.shape[0] > 50 and q_image.shape[1] > 50:  # Only split if large enough\n",
    "            quarters = quarter_image(q_image)\n",
    "            for j, q in enumerate(quarters):\n",
    "                quartered_queue.append((q, f\"{base_name}_q{i}\", j))  # Add new quarters to the stack\n",
    "    elif image_queue:\n",
    "        # Quarter the next image in the original queue\n",
    "        image_path = image_queue.pop(0)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image.shape[0] > 50 and image.shape[1] > 50:  # Only split if large enough\n",
    "            quarters = quarter_image(image)\n",
    "            base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            for i, q in enumerate(quarters):\n",
    "                quartered_queue.append((q, base_name, i))  # Add quarters to the stack\n",
    "    next_image()  \n",
    "def on_no_clicked(b):\n",
    "    if quartered_queue:\n",
    "        quartered_queue.pop() \n",
    "    next_image()  \n",
    "\n",
    "def on_save_clicked(b):\n",
    "    if quartered_queue:\n",
    "        q_image, base_name, i = quartered_queue.pop()\n",
    "        save_path = os.path.join(output_folder, f\"{base_name}_q{i}.png\")\n",
    "        cv2.imwrite(save_path, q_image)  \n",
    "        print(f\"Saved: {save_path}\")\n",
    "    next_image()  \n",
    "\n",
    "# Create buttons\n",
    "yes_button = Button(description=\"Yes (Quarter)\", button_style='success', layout=Layout(width='150px'))\n",
    "no_button = Button(description=\"No (Skip)\", button_style='warning', layout=Layout(width='150px'))\n",
    "save_button = Button(description=\"Save (Final Cusp)\", button_style='primary', layout=Layout(width='150px'))\n",
    "\n",
    "yes_button.on_click(on_yes_clicked)\n",
    "no_button.on_click(on_no_clicked)\n",
    "save_button.on_click(on_save_clicked)\n",
    "\n",
    "controls = HBox([yes_button, no_button, save_button])\n",
    "display(VBox([output, controls]))\n",
    "\n",
    "# Start processing\n",
    "next_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb9a17a095f47488928d8c5aa3d6078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(), HBox(children=(Button(button_style='primary', description='Save Cropped', layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_folder = '/Users/rfalcao/Documents/ClearCuspsCroppedRotated'  \n",
    "output_folder = \"/Users/rfalcao/Documents/Separated Clear Cusps\"  \n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load images\n",
    "image_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.tif'))]\n",
    "image_queue = image_files[:]  # Initialize queue with original images\n",
    "\n",
    "output = Output()\n",
    "\n",
    "# Global variables for selected region\n",
    "selected_region = None\n",
    "\n",
    "# Function to display image\n",
    "def update_display(image, title):\n",
    "    global selected_region\n",
    "    selected_region = None  # Reset selected region\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))  # Larger plot size\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Callback function for RectangleSelector\n",
    "        def on_select(eclick, erelease):\n",
    "            global selected_region\n",
    "            x1, y1 = int(eclick.xdata), int(eclick.ydata)\n",
    "            x2, y2 = int(erelease.xdata), int(erelease.ydata)\n",
    "            selected_region = (min(x1, x2), min(y1, y2), abs(x2 - x1), abs(y2 - y1))  # (x, y, width, height)\n",
    "            print(f\"Selected region: {selected_region}\")\n",
    "\n",
    "        # Add RectangleSelector\n",
    "        rs = RectangleSelector(ax, on_select, button=[1], minspanx=5, minspany=5, spancoords='pixels', interactive=True)\n",
    "        plt.connect('key_press_event', rs)\n",
    "        plt.show()\n",
    "        print(\"Draw a box by clicking and dragging on the image.\")\n",
    "\n",
    "# Function to process next image\n",
    "def next_image():\n",
    "    if image_queue:\n",
    "        image_path = image_queue[0]\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        update_display(image, f\"Inspecting: {os.path.basename(image_path)}\")\n",
    "    else:\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            print(\"All images processed!\")\n",
    "\n",
    "# Button callbacks\n",
    "def on_save_clicked(b):\n",
    "    global selected_region\n",
    "    if selected_region and image_queue:\n",
    "        image_path = image_queue.pop(0)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        x, y, w, h = selected_region\n",
    "        cropped_image = image[y:y+h, x:x+w]  # Extract the selected region\n",
    "        save_path = os.path.join(output_folder, f\"cropped_{os.path.basename(image_path)}\")\n",
    "        cv2.imwrite(save_path, cropped_image)  # Save the cropped image\n",
    "        print(f\"Saved: {save_path}\")\n",
    "        selected_region = None  # Reset selected region\n",
    "    next_image()\n",
    "\n",
    "def on_skip_clicked(b):\n",
    "    if image_queue:\n",
    "        image_queue.pop(0)  # Skip the current image\n",
    "    next_image()\n",
    "\n",
    "# Create buttons\n",
    "save_button = Button(description=\"Save Cropped\", button_style='primary', layout=Layout(width='150px'))\n",
    "skip_button = Button(description=\"Skip\", button_style='warning', layout=Layout(width='150px'))\n",
    "\n",
    "save_button.on_click(on_save_clicked)\n",
    "skip_button.on_click(on_skip_clicked)\n",
    "\n",
    "controls = HBox([save_button, skip_button])\n",
    "display(VBox([output, controls]))\n",
    "\n",
    "# Start processing\n",
    "next_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2/8\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 24s/step - accuracy: 0.6250 - loss: 0.6836"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Define folders\n",
    "input_folder = '/Users/rfalcao/Documents/Separated Clear Cusps'  # Folder with images\n",
    "output_folder = \"/Users/rfalcao/Documents/FirstTrainPass\"  # Folder to save results\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# Function to load and preprocess image\n",
    "# def load_and_preprocess_image(filepath, label):\n",
    "#     image = load_img(filepath, target_size=(224, 224))\n",
    "#     image = img_to_array(image) / 255.0  # Normalize\n",
    "#     image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "#     return image, tf.convert_to_tensor(label, dtype=tf.float32)\n",
    "\n",
    "# # Create TensorFlow dataset\n",
    "# def create_dataset(image_folder, labels_dict):\n",
    "#     image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.tif'))]\n",
    "#     image_paths = [os.path.join(image_folder, f) for f in image_files]\n",
    "#     image_labels = [labels_dict.get(f, 0) for f in image_files]  # Default to 0 if missing\n",
    "    \n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((image_paths, image_labels))\n",
    "    \n",
    "#     def process_path(file_path, label):\n",
    "#         image, label = tf.py_function(func=load_and_preprocess_image, inp=[file_path, label], Tout=(tf.float32, tf.float32))\n",
    "#         image.set_shape((224, 224, 3))  # Explicitly set shape\n",
    "#         label.set_shape(())  # Scalar label\n",
    "#         return image, label\n",
    "\n",
    "#     dataset = dataset.map(process_path)\n",
    "#     dataset = dataset.batch(8).shuffle(len(image_files))\n",
    "#     return dataset\n",
    "\n",
    "\n",
    "dataset = create_dataset(input_folder, labels)\n",
    "# Function to load and preprocess image\n",
    "def load_and_preprocess_image(filepath, label):\n",
    "    filepath = filepath.numpy().decode(\"utf-8\")  # Convert Tensor to string\n",
    "    image = load_img(filepath, target_size=(224, 224))\n",
    "    image = img_to_array(image) / 255.0  # Normalize\n",
    "    return image, np.float32(label)\n",
    "\n",
    "# Wrap the function to work within TensorFlow's dataset pipeline\n",
    "def tf_load_and_preprocess_image(filepath, label):\n",
    "    return tf.py_function(load_and_preprocess_image, [filepath, label], [tf.float32, tf.float32])\n",
    "\n",
    "# Create TensorFlow dataset\n",
    "def create_dataset(image_folder, labels_dict):\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.tif'))]\n",
    "    image_paths = [os.path.join(image_folder, f) for f in image_files]\n",
    "    image_labels = [labels_dict.get(f, 0) for f in image_files]  # Default to 0 if missing\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, image_labels))\n",
    "    \n",
    "    def process_path(file_path, label):\n",
    "        image, label = tf.py_function(func=load_and_preprocess_image, inp=[file_path, label], Tout=(tf.float32, tf.float32))\n",
    "        image.set_shape((224, 224, 3))  # Explicitly set shape\n",
    "        label.set_shape(())  # Scalar label\n",
    "        return image, label\n",
    "\n",
    "    dataset = dataset.map(process_path)\n",
    "    dataset = dataset.batch(8).shuffle(len(image_files))\n",
    "    return dataset\n",
    "dataset = create_dataset(input_folder, labels)\n",
    "# Load pre-trained ResNet50\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "num_epochs = 5\n",
    "model.fit(dataset, epochs=num_epochs)\n",
    "\n",
    "# Function to generate saliency maps\n",
    "def generate_saliency_map(image, model):\n",
    "    image = tf.convert_to_tensor(image[None, ...])\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        prediction = model(image, training=False)\n",
    "    grads = tape.gradient(prediction, image)\n",
    "    saliency = tf.reduce_max(tf.abs(grads), axis=-1)[0]\n",
    "    return saliency.numpy()\n",
    "\n",
    "# Function to plot saliency maps\n",
    "def plot_saliency_map(image, saliency):\n",
    "    image = np.array(image)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(saliency, cmap='hot')\n",
    "    plt.title(\"Saliency Map\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Generate and plot saliency maps for a few images\n",
    "for image_path, label in zip(list(labels.keys())[:3], list(labels.values())[:3]):\n",
    "    image, _ = load_and_preprocess_image(os.path.join(input_folder, image_path), label)\n",
    "    saliency = generate_saliency_map(image, model)\n",
    "    plot_saliency_map(image, saliency)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-m2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
